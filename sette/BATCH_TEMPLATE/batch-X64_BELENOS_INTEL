#!/usr/bin/env bash

#SBATCH -J sette
#SBATCH -o sette.%j.out
#SBATCH -e sette.%j.err
#SBATCH --export=ALL
#SBATCH --parsable
#SBATCH --exclusive
#SBATCH -N 1

#SBATCH -p normal256
#SBATCH --time=01:00:00
##SBATCH --time=00:15:00

##SBATCH -A smer
#SBATCH -A cmems

##SBATCH --qos=normal
#SBATCH --qos=coper

set +x

# Test specific settings. Do not hand edit these lines; the fcm_job.sh script will set these
# (via sed operating on this template job file). 
#
  echo " ";
  OCORES=NPROCS
  XCORES=NXIOPROCS
  O_PER_NODE=32
  X_PER_NODE=8
  if [ $XCORES -le $X_PER_NODE ]; then X_PER_NODE=$XCORES; fi
  if [ $OCORES -le $O_PER_NODE ]; then O_PER_NODE=$OCORES; fi
  export SETTE_DIR=DEF_SETTE_DIR

###############################################################
#
#
# load sette functions (only post_test_tidyup needed)
#
  . ${SETTE_DIR}/all_functions.sh
###############################################################
#
# Don't remove neither change the following line
# BODY
#
# Test specific settings. Do not hand edit these lines; the fcm_job.sh script will set these
# (via sed operating on this template job file). Note that the number of compute nodes required
# is also set by the fcm_job.sh on the PBS select header line above.
#
# These variables are needed by post_test_tidyup function in all_functions.sh
#
  export MPIRUN="srun"
  export INPUT_DIR=DEF_INPUT_DIR
  export CONFIG_DIR=DEF_CONFIG_DIR
  export TOOLS_DIR=DEF_TOOLS_DIR
  export NEMO_VALIDATION_DIR=DEF_NEMO_VALIDATION
  export NEW_CONF=DEF_NEW_CONF
  export CMP_NAM=DEF_CMP_NAM
  export TEST_NAME=DEF_TEST_NAME
  export EXE_DIR=DEF_EXE_DIR

  # Load environment if exists
  env_file=`find ${TOOLS_DIR}/../arch -name arch-${CMP_NAM}.env`
  if [ -f "${env_file}" ] ; then
     echo "Load environment file arch-${CMP_NAM}.env"
     . ${env_file}
  fi

  ulimit -a
  ulimit -s unlimited
#
# end of set up
###############################################################
#
# change to the working directory 
#
  cd ${EXE_DIR}
  if [[ ${NEW_CONF} =~ "ICE_AGRIF" ]]; then
    sed -i'' -e 's/detect_missing_value="true"/detect_missing_value="false"/' field_def_nemo-ice.xml
  fi
  echo Running on host `hostname`
  echo Time is `date`
  echo Directory is `pwd`
# 
#  Run the parallel MPI executable 
#
  echo "Running time ${MPIRUN} ./nemo"
#
  if [ $XCORES -gt 0 ]; then
#
#  Run MPMD case
#
     #XIOS will run on a separate node so will run in parallel queue
     if [ $XCORES -gt 0 ] && [ -f ${XIOS_DIR}/bin/xios_server.exe ]; then
        cp -a ${XIOS_DIR}/bin/xios_server.exe .
     fi

     # SRUN
     cat > ./config.file <<-EOF
0-$((OCORES-1)) ./nemo
${OCORES}-$((TOTAL_NPROCS-1)) ./xios_server.exe
EOF
     # MPIEXEC
#    cat > ./config.file <<-EOF
#-n ${OCORES} ./nemo
#-n ${XCORES} ./xios_server.exe
#EOF
     $MPIRUN --ntasks=TOTAL_NPROCS --multi-prog config.file
  else
#
# Run SPMD case
#
    $MPIRUN --ntasks=TOTAL_NPROCS ./nemo
  fi
#

#
(post_test_tidyup) || exit $?
# END_BODY
# Don't remove neither change the previous line
